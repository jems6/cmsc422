{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "\n",
    "\n",
    "# Pseudo Code\n",
    "\n",
    "# store the documents as lists of words, one after another, one list per doc\n",
    "\n",
    "# For each paper source in 20_newsgroups\n",
    "#     For each paper in the source\n",
    "#         remove the first 4 lines (lines starting with Newsgroup, document_id, From, Subject)\n",
    "#         save into dataset (source, paper)\n",
    "# for each source in dataset\n",
    "#     split in half, (train, test)\n",
    "\n",
    "# dataset complete, good to go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudo Code\n",
    "\n",
    "# Naive Bayes Implementations\n",
    "\n",
    "# returns V, log P(c), log P(w|c)\n",
    "def train_naive_bayes(D, C): # D is the dataset, C is the classes\n",
    "    # Initialize the count of each class\n",
    "    ndoc = sum([len(D[c]) for c in D]) # for class in the dataset count the number of documents and sum them\n",
    "    logprior = {} # initialize the logprior\n",
    "    loglikelihood = {} # initialize the loglikelihood\n",
    "    bigdoc = {} # initialize the bigdoc\n",
    "    V = set() # initialize the vocabulary\n",
    "    for c in C: # for each class in the classes\n",
    "        ndoc_c = len(D[c]) # count the number of documents in the class\n",
    "        logprior[c] = math.log(ndoc_c / ndoc)\n",
    "        D_c = set([word for doc in D[c] for word in doc]) # get the words in the class\n",
    "        bigdoc[c] = [doc for doc in D[c]]\n",
    "        V.update(D_c) # add the words to the vocabulary\n",
    "        for word in V:\n",
    "            pass\n",
    "\n",
    "\n",
    "    return V, logprior, loglikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_naive_bayes(testdoc, C, V, logprior, loglikelihood):\n",
    "    summ = {}\n",
    "    for c in C:\n",
    "        sum[c] = logprior[c]\n",
    "        for i in testdoc:\n",
    "            word = testdoc[i] # get the word, def wrong btw\n",
    "            if word in V:\n",
    "                sum[c] += loglikelihood[word][c] \n",
    "    return summ.index(max(summ)) # return the argmax"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
